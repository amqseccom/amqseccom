
# Welcome

This ePortfolio integrates the knowledge and skills I gained and developed throughout the years of studying a Computer Science program at Southern New Hampshire University (SNHU). It represent my growth in the program and gained honor rolls from high-quality outcomes. The ePortfolio was designed and developed with a professional-quality written and a visual communication demonstrative of my capacities and abilities in a coherent, technically sound, and appropriately adapted to an specific technical audience and context.

### <u>Table of Content</u>

&nbsp;[Professional Self-Assessment](#professional-self-assessment)<br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[_Portfolio Considerations_](#portfolio-considerations "Portfolio Considerations")<br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[_Preparing For The Future_](#preparing-for-the-future "Preparing for the Future")<br/>
&nbsp;[Refinement Plan and Code Review](#refinement-plan-and-code-review)<br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[_Code Review Videos Link_](#artifacts-code-review-videos-link)<br/>
&nbsp;[Software Design and Engineering](#software-design-and-engineering)<br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[_Artifact Software Design and Engineering_](#artifact-software-design-and-engineering "Artifact Software Design and Engineering")<br/>
&nbsp;[Algorithms and Data Structure](#algorithms-and-data-structure)<br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[_Artifact Algorithms and Data Structure_](#artifact-algorithms-and-data-structures "Artifact Algorithms and Data Structure")<br/>
&nbsp;[Databases](#databases "Databases")<br/>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[_Artifact Databases_](#artifact-databases "Artifact Databases")<br/>

# Professional self-assessment

I began my computer science journey starting in April 2019.  I decided on the computer science program because of my passion for working with and technology and software.  While in this program I gained knowledge and skills in many different applications.  I have improved my organization skills, attention to detail and understanding how workflow works when dealing with software development.  With going through this program, I have learned how to implement code reviews, best practices and security standards to all my code.  I also, learned the importance of Software Development Lifecycle and how this is implemented to enterprise scale operations.  By incorporating the SDLC into my coding practices I can correctly use pseudocode, Flow charts and algorithms.

Throughout the program has led to an increased capacity for learning with being able to bring solutions to problems when data, software and technology are involved.  While completing this program I have gained many skills and then throughout the courses my capacity for those sills increased as well.  Learning and implementing how agile and waterfall developments works into my projects as well as using fundamentally computer science foundations to build them.

Skills I learned over the course in relation to the development pipe line was planning and finding what the needs of the project are.  In the screen shot below is the beginning on the planning phase for a database for a pizza company.  These planning phase makes sure all needs are covered and implemented into the planning phase.  This allows a check list to go over as each class is built in the desired database.

<div style="text-align: center;">
    <img src="assets/images/Screenshot%20(235).png" width="720px" title="test" />
    <p><em>IT- 235</em></p>
</div>

## Portfolio Considerations

## Preparing for the Future

My ePortfolio demonstates my skills and abiliters as a software devlopper.  The ePortfolio also, demostarts the ability to adpart and learn with many different projects and classes using a varity of skills and programming languages.  I look forward to leaning, growing and am driven to complete work in a quality focused manner.

# Refinement Plan and Code Review

## Artifacts Code Review Videos Link

# Software Design and Engineering

The artifact selected for the software design and engineering category is the pymongo CRUD aplication from Salvare Search for Rescue Web App project.  The aplciations goal is to create the functionitily of CRUD for use with the mongodb database.  This showcaseese software design and engineering skills by examding the Python PyMongo drivers with dash framework intigartion.  With the CRUD module exanded with a Query and List funtion, this allows the data to be manipulated in a more streamlined way.

## Artifact Software Design and Engineering

[Link to Pymongo CRUD APLICATION](https://github.com/daimon2008/Capstone/blob/master/docs/shelter.py)

<div style="text-align: center;">
    <img src="assets/images/Screenshot%20(232).png" width="720px" title="test" />
    <p><em>Adding LS and CRUD</em></p>
</div>

# Algorithms and Data Structure

The artifact selectedd for the Alogorithim and data structure category is the Pymongo Script created and used in the Salvare Search for Rescue Web App project.  I selected this artifact becacuse its consists of design considerations and creating an API to both use the artifact from software design and enineering and theailbity to quickly call an APU and manipulate and test data.  This showcases data structure skills with creating a script to quickly excute the expanded CRUD funtionity with the previous catoeries Query and List functions.

## Artifact Algorithms and Data Structures

[Link to Pymongo Script](https://github.com/daimon2008/Capstone/blob/master/docs/projectone(1).ipynb)

<div style="text-align: center;">
    <img src="assets/images/Screenshot%20(233).png" width="720px" title="test" />
    <p><em>Modifying Script to work with addition to LS in CRUD</em></p>
</div>

# Databases

The main artifact selected for the database category is the data from Salver Search for Rescue web app.  The app uses restful API and http protocols to take data from a mongo DB and create a map interface using Lat and Lon coordinates.  My improvement for the artifact was taking the data from the artifact and create a system to analyze the data.  First was creating a way to be able to access the data, with that I uploaded the .cvs file to GitHub.  Then I created a HTML, JS and, CSS web page to import and visualize that data.  Using chat.js I was able to create a graph using specific entities to a color to make the visualization easier.  So, it is easier to see what are dogs and cats, and where their age in weeks falls on the graph.  This showcases skills with data analytics and being able to implements APIâ€™s and valuations the information.  This could easily be scaled up in a way to import vast amounts of data from AWS or Azure and then create visualizations based on hypothetical questions a company or client may have.

## Artifact Databases

<div style="text-align: center;">
    <img src="assets/images/Screenshot%20(237).png" width="720px" title="test" />
    <p><em>Data Analysis and Visulation</em></p>
</div>

#### Here is a built webpage using chart.js and API to visulaize and interface the data into a webpage.

[Database Data](https://daimon2008.github.io/database/)

[Link to the Web Fiiles](https://github.com/daimon2008/database)

<dl>
<dt>Name</dt>
<dd>Paul Schwartz</dd>
<dt>Born</dt>
<dd>1986</dd>
<dt>Birthplace</dt>
<dd>Kissimmee, FL</dd>
</dl>

